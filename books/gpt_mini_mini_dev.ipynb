{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7847dcb9-cbce-4e2e-8974-128fdf8ae94a",
   "metadata": {},
   "source": [
    "# GPT mini mini: Treinando meu primeiro transformer de Zero (Parte 1)\n",
    "\n",
    "- Motivação \n",
    "- Setup de desenvolvimento\n",
    "- Creação de Dataloader para Pytorch\n",
    "- Definição do problema de modelos de linguagem \n",
    "- Definição do modelo\n",
    "- Codificação posicional \n",
    "- Generação de texto\n",
    "- Mecanismo de atenção\n",
    "- Modelo GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df747928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pedrodiamel/gpt_mini_mini/blob/main/books/gpt_mini_mini_dev.ipynb\">\n",
       "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
       "</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\n",
    "\"\"\"\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pedrodiamel/gpt_mini_mini/blob/main/books/gpt_mini_mini_dev.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a18c30-9102-40c1-8e8d-f9378277270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  5 01:14:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4500    On   | 00000000:01:00.0  On |                  Off |\n",
      "| 30%   37C    P5    57W / 200W |    613MiB / 20470MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4500    On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 30%   31C    P8    12W / 200W |     10MiB / 20470MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ebb71-c585-4e72-b562-22a1cb47f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59434f-7541-4d04-be98-afb1c832c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    #!pip install git+https://github.com/pedrodiamel/gpt_mini_mini\n",
    "    !{sys.executable} -m pip install \"git+https://github.com/pedrodiamel/gpt_mini_mini\"\n",
    "    !mkdir -p /.datasets/llms/brasiliansong/\n",
    "    !wget -P /.datasets/llms/brasiliansong/ https://raw.githubusercontent.com/pedrodiamel/gpt_mini_mini/main/data/brasiliansong/input.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6af87ed-e178-42a7-84ae-c503c38f7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# TORCH MODULE\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# LOCAL MODULE\n",
    "from llms.datasets.datasets import CharDataset\n",
    "from llms.transformer import NeuralNetTransformer\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de5f683-6dd7-481a-a21d-6edd0075f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500-greatest-songs-of-all-time.zip  input_000.txt\n",
      "bad-bunny-lyrics.zip\t\t    input_001.txt\n",
      "bossa-nova-lyrics\t\t    input_spotify.txt\n",
      "bossa-nova-lyrics.zip\t\t    input.txt\n",
      "brazilian-songs-lyrics\t\t    letras-de-musicas-brasileiras.zip\n",
      "brazilian-songs-lyrics.zip\t    letras-de-rap-en-español.zip\n",
      "datasets.txt\t\t\t    spotify-million-song\n",
      "eminem-lyrics-from-all-albums.zip   spotify-million-song-dataset.zip\n"
     ]
    }
   ],
   "source": [
    "!ls /.datasets/llms/brasiliansong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4012f864-37fb-4e3f-90af-ad818df857ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/.datasets/llms/brasiliansong/input.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45e88bb-175a-4dc2-9e16-3fe8264fd5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068f0713-1796-4497-a859-9042bcb59d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de caracteres 8990763\n"
     ]
    }
   ],
   "source": [
    "print(\"quantidade de caracteres\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177e7b6b-ab94-4926-8de5-031e61e399c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Beijos de Rua:\n",
      "Acabou outra vez. \n",
      "Foi cena repetida. \n",
      "Um tchau com gosto de fica. \n",
      "Me chamaram aqui pra sair. \n",
      "Nem no clima eu to. \n",
      "Mas só de raiva eu vou. \n",
      "Meu coração nem ia. \n",
      "Mas só que a teimosia. \n",
      "Chegou em mim parou, parou. \n",
      "Na primeira boca já senti remorso. \n",
      "Beijando mal de propósito. \n",
      "Torcendo pra acabar. \n",
      "O que eu nem devia começar. \n",
      "10 de beijos de rua. \n",
      "Não valem metade do seu. \n",
      "No canto da boca. \n",
      "Imagina na boca. \n",
      "10 beijos de rua. \n",
      "Não causa efeito. \n",
      "De quando me abraça com roup\n"
     ]
    }
   ],
   "source": [
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5822b5f9-6e53-452f-8827-60996c808457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡ª°²´º¿ÀÁÂÃÇÈÉÊËÍÒÓÔÕÚßàáâãäçèéêëìíîïñòóôõöùúûüāœ​–—―‘’“”„…♪♫ﬂ﻿\n"
     ]
    }
   ],
   "source": [
    "voc = sorted(list(set(data)))\n",
    "print(len(voc))\n",
    "print(\"\".join(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4bab5b9-80fb-487e-bf4e-92821f7085b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc = [w for l in data.split(\"\\n\") for w in l.split(\" \")]\n",
    "# voc = sorted(list(set(voc)))\n",
    "\n",
    "# print(len(voc))\n",
    "# print(\"\".join(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0bd4476-e5e3-4d77-b08d-c8a1f8f768a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 75, 121, 2, 79, 68, 82, 82, 78, 64, 75]\n",
      "Olá pessoal\n"
     ]
    }
   ],
   "source": [
    "# vamos tokenizar \n",
    "stoi = {s:i for i,s in enumerate(voc)}\n",
    "itos = {i:s for i,s in enumerate(voc)}\n",
    "\n",
    "encoder = lambda s: [stoi[c] for c in s] \n",
    "decoder = lambda t: \"\".join([itos[i] for i in t])\n",
    "\n",
    "print(encoder(\"Olá pessoal\"))\n",
    "print(decoder(encoder(\"Olá pessoal\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "581b4791-58d5-42e8-b7f0-da22429e15bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho do voc 50257\n",
      "[30098, 6557, 279, 408, 78, 282]\n",
      "Olá pessoal\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "print(\"tamanho do voc\", enc.n_vocab)\n",
    "print(enc.encode(\"Olá pessoal\"))\n",
    "print(enc.decode(enc.encode(\"Olá pessoal\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b70add-e933-45e8-a2a6-251473811a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38607466-703c-42c4-a565-a25f077bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, pathname, block_size, train=True, download=False):\n",
    "        \"\"\"CharDataset\n",
    "        Args:\n",
    "            pathname (str): path to dataset\n",
    "            block_size (int): block size for context window\n",
    "            train (bool): train or test\n",
    "            download (bool): download dataset if not found\n",
    "        Ref:\n",
    "            https://github.com/facebookresearch/xformers/blob/main/examples/microGPT.py\n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.isfile(pathname):\n",
    "            raise FileNotFoundError(\"Dataset not found.\")\n",
    "\n",
    "        with open(pathname, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = f.read()\n",
    "\n",
    "        voc = sorted(list(set(data)))\n",
    "        vocab_size = len(voc)\n",
    "\n",
    "        self.stoi = {ch: i for i, ch in enumerate(voc)}\n",
    "        self.itos = {i: ch for i, ch in enumerate(voc)}\n",
    "\n",
    "        n = int(0.9 * len(data)) # 90% para treinamento (99% treinamento)\n",
    "        data = data[:n] if train else data[n:]\n",
    "        data_size = len(data)\n",
    "\n",
    "        self.pathname = pathname\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "        self.count = data_size\n",
    "        self.voc = voc\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count - self.block_size\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        chunk = self.data[i : i + self.block_size + 1]\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "\n",
    "        # src and target are off by one, we want the model to predict the next word\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "    def to_tokens(self, message, device):\n",
    "        return torch.tensor([self.stoi[s] for s in message], dtype=torch.long)[None, ...].to(device)\n",
    "\n",
    "    def from_tokens(self, tokens):\n",
    "        return \"\".join([self.itos[int(i)] for i in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90a03c36-a4bf-4fed-8932-a5f8af80efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899069\n"
     ]
    }
   ],
   "source": [
    "block_size=8\n",
    "dataset = CharDataset(DATASET_PATH, block_size, train=False)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0d37f5f-31db-498e-b358-3e14e8bb6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([76, 68,  2, 68, 77, 70, 64, 77]) me engan\n",
      "tensor([68,  2, 68, 77, 70, 64, 77, 78]) e engano\n"
     ]
    }
   ],
   "source": [
    "x,y = dataset[0]\n",
    "print(x, dataset.from_tokens(x))\n",
    "print(y, dataset.from_tokens(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f757139-1cd7-4e3b-a49e-052f8e372a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224767\n",
      "224767.25\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8 # context windows \n",
    "workers = 1\n",
    "\n",
    "# Create dataset\n",
    "dataset = CharDataset(DATASET_PATH, block_size, train=False)\n",
    "\n",
    "# Load data\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    sampler=RandomSampler(dataset),\n",
    "    num_workers=workers,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "print(len(dataloader))\n",
    "print(len(dataset)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "066bc331-bb59-4061-852b-59d4bf185e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x \\in  torch.Size([4, 8])\n",
      "y \\in  torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for epoch in range(epochs)\n",
    "# uma epochs \n",
    "for x,y in dataloader:\n",
    "    print(\"x \\in \", x.shape)\n",
    "    print(\"y \\in \", y.shape)\n",
    "\n",
    "    # yh = f(x)_w = [yh]_[B,T,Cv]  \n",
    "    # J = CE(y, yh)\n",
    "\n",
    "    # pytorch opt\n",
    "    # W^(t+1) = W^t - lr*grad(J) (*) \n",
    "    # opt.zero_grad()\n",
    "    # J.backword()\n",
    "    # opt.step()\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b27069-1edf-4439-b7c8-ab9fa84caa11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b35c3e9-7aea-4e5e-9674-b341272a6935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "yh torch.Size([4, 8, 160])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class GPTmm(nn.Module):\n",
    "\n",
    "    def __init__(self, voc_size):\n",
    "        super().__init__()\n",
    "\n",
    "        k=voc_size\n",
    "        self.emb = nn.Embedding(voc_size, k)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # [x]_(B,T)\n",
    "        # [yh]_(B,T,Cv)\n",
    "        yh = self.emb(x)\n",
    "\n",
    "        \n",
    "        return yh\n",
    "\n",
    "\n",
    "voc_size = dataset.vocab_size\n",
    "f = GPTmm(voc_size)\n",
    "print(x.shape)\n",
    "yh = f(x)\n",
    "\n",
    "print(\"yh\", yh.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "166b5e69-c6e6-41b2-9ddb-63c80fc4b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW( f.parameters(), lr=1e-3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3741bcca-8096-4beb-b33e-5d71725c1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "5.172210693359375\n",
      "4.915787696838379\n",
      "4.8538498878479\n",
      "5.1753692626953125\n",
      "5.0744547843933105\n",
      "4.736363410949707\n",
      "4.945469856262207\n",
      "5.241998672485352\n",
      "5.066843032836914\n",
      "5.103704929351807\n",
      "4.980006217956543\n",
      "4.760480880737305\n",
      "4.814445972442627\n",
      "5.07875919342041\n",
      "5.119041442871094\n",
      "4.839418888092041\n",
      "4.958718776702881\n",
      "4.954410076141357\n",
      "4.830076694488525\n",
      "5.0022664070129395\n",
      "4.921172142028809\n",
      "4.722481727600098\n",
      "4.558915615081787\n",
      "4.770347595214844\n",
      "4.54874849319458\n",
      "4.726893901824951\n",
      "4.735639572143555\n",
      "4.409339904785156\n",
      "4.56466817855835\n",
      "4.341578006744385\n",
      "4.418620586395264\n",
      "4.308345317840576\n",
      "4.400155544281006\n",
      "4.572384357452393\n",
      "4.38454532623291\n",
      "4.264686584472656\n",
      "4.5832977294921875\n",
      "4.251803398132324\n",
      "4.47282075881958\n",
      "4.664233207702637\n",
      "4.496827602386475\n",
      "4.460476398468018\n",
      "4.590721607208252\n",
      "4.337376594543457\n",
      "4.1955695152282715\n",
      "4.213145732879639\n",
      "4.490564346313477\n",
      "4.604422092437744\n",
      "4.428208351135254\n",
      "4.094630718231201\n",
      "4.347883701324463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(max_iter=100):\n",
    "\n",
    "    f.train()\n",
    "    for i,(x,y) in enumerate(dataloader):\n",
    "        # yh = f(x)_w = [yh]_(B,T,Cv) (*) Attention \n",
    "        # J = CE(y, yh)\n",
    "    \n",
    "        yh = f(x) # [yh]_(B,T,Cv)\n",
    "        J = F.cross_entropy(yh.view(-1, voc_size), y.view(-1))\n",
    "    \n",
    "        # pytorch opt\n",
    "        # W^(t+1) = W^t - lr*grad(J) (1)\n",
    "        # opt.zero_grad()\n",
    "        # J.backward() => grad(J)\n",
    "        # opt.step()\n",
    "    \n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        J.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(J.item()) \n",
    "\n",
    "        if i > max_iter:\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch \", epoch)\n",
    "    train(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ff973-7d83-4be0-b51d-c4139d6bd4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d64f55-6e31-41d9-b056-cd40a4911b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8009c47-e324-42c6-a982-432bee7a2852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
